# -*- coding: utf-8 -*-
"""DAV.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xwMUK2r5OvcNBdk7ieN7SmeAS2mbzMvz

Q1  Write programs in Python using NumPy library to do the following:
"""

import numpy as np

import pandas as pd

"""Create a two dimensional array, ARR1 having random values from 0 to 1. Compute the mean, standard
deviation, and variance of ARR1 along the second axis.
"""

ARR1 = np.random.rand(10).reshape(5,2)
ARR1

ARR1.mean(axis = 1)

np.std(ARR1, axis = 1)

np.var(ARR1, axis = 1)

""" Create a 2-dimensional array of size m x n integer elements, also print the shape, type and data type of
the array and then reshape it into an n x m array, where n and m are user inputs given at the run time.

"""

m = int(input())
n = int(input())
ARR2 = np.random.randint(10,size = (m,n))
ARR2

ARR2.shape

type(ARR2)

ARR2.dtype

ARR2.reshape(n,m)

"""Test whether the elements of a given 1D array are zero, non-zero and NaN. Record the indices of these
elements in three separate arrays.
"""

arr = np.array([1,2,3,0,8,np.nan, np.nan])
arr

np.array([i for i in range(len(arr)) if arr[i] == 0])

np.array([i for i in range(len(arr)) if arr[i] >0])

np.array([i for i in range(len(arr)) if arr[i] is np.nan])

"""Create three random arrays of the same size: Array1, Array2 and Array3. Subtract Array 2 from Array3
and store in Array4. Create another array Array5 having two times the values in Array1. Find Covariance and Correlation of Array1 with Array4 and Array5 respectively

"""

Array1 = np.random.randint(10,size = (1,10))
Array3 = np.random.randint(10,size = (1,10))
Array2 = np.random.randint(10,size = (1,10))

Array4 = Array3 - Array2
Array4

Array5 =2*Array1
Array5

np.cov(Array1,Array5)

np.corrcoef(Array1,Array5)

"""Create two random arrays of the same size 10: Array1, and Array2. Find the sum of the first half of both
the arrays and product of the second half of both the arrays.

"""

Array1 = np.random.randint(10,size = 10)
Array2 = np.random.randint(10, size = 10)

Array1[:len(Array1)//2] + Array2[:len(Array2)//2]

Array1[Array1.size//2:]*Array2[Array2.size//2:]

"""Create an array with random values. Determine the size of the memory occupied by the array"""

array = np.random.rand(100)

array.nbytes

"""Create a 2-dimensional array of size m x n having integer elements in the range (10,100). Write
statements to swap any two rows, reverse a specified column and store updated array in another
variable

"""

array = np.random.randint(10,100,size = (10,7))
array

array[[1,0]] = array[[0,1]]

array

col_index  = 0
array[:,col_index] = array[:,col_index][::-1]
array

"""Q2 Do the following using PANDAS Series

Create a series with 5 elements. Display the series sorted on index and also sorted on values seperately
"""

s = pd.Series(np.random.randint(1,10,5) ,index = [3,2,1,0,4])
s

s.sort_index()

s.sort_values()

"""Create a series with N elements with some duplicate values. Find the minimum and maximum ranks
assigned to the values using ‘first’ and ‘max’ methods
"""

s = pd.Series([1,2,3,4,3,3,3,3,3])
s

s.rank()

s.rank(method='max')

s.rank(method='first')

"""Display the index value of the minimum and maximum element of a Serie"""

s.idxmin()

s.idxmax()

"""Q3Create a data frame having at least 3 columns and 50 rows to store numeric data generated using a random
function. Replace 10% of the values by null values whose index positions are generated using random function.
Do the following:
"""

df = pd.DataFrame(np.random.randint(1,10,size = (50,3)))

df

"""generate random index and column index"""

np.random.randint(0,df.shape[1])

np.random.randint(0,df.shape[0])

df.iloc[np.random.randint(0,df.shape[0]),np.random.randint(0,df.shape[1])]= np.nan
df

i = 0
while(i <= (10/100)*df.size):
    df.iloc[np.random.randint(0,df.shape[0]),np.random.randint(0,df.shape[1])] = np.nan
    i += 1

"""dentify and count missing values in a data frame"""

df.isnull()

df.isnull().sum()

""" Drop the column having more than 5 null values"""

df.dropna(thresh = 5, axis = 1, inplace = True)

df.shape

"""Identify the row label having maximum of the sum of all values in a row and drop that row"""

df.sum(axis = 1).idxmax()

df.drop(df.sum(axis = 1).idxmax())

""". Sort the data frame on the basis of the first column

"""

df.sort_values([0])

"""Remove all duplicates from the first column."""

df.drop_duplicates([0]).sort_values([0])

"""Find the correlation between first and second column and covariance between second and third
column.
"""

df[0].corr(df[1])

df[0].cov(df[1])

"""Discretize the second column and create 5 bins."""

df["cut"] = pd.cut(df[1],bins = 5)
df

"""Q7  Consider the following data frame containing a family name, gender of the family member and her/his monthly
income in each record.
FamilyName Gender MonthlyIncome (Rs.)
Shah Male 44000.00
Vats Male 65000.00
Vats Female 43150.00
Kumar Female 66500.00
Vats Female 255000.00
Kumar Male 103000.00
Shah Male 55000.00
Shah Female 112400.00
Kumar Female 81030.00
Vats Male 71900.00
Write a program in Python using Pandas to perform the following:
"""

df = pd.DataFrame({"Family Name": ['Shah',"Vats","Vats","Kumar","Vats","Kumar","Shah","Shah","Kumar","Vats"],"Gender":['M','M','F','F','F','M','M','F','F','M'],"Income":[44000,65000,43150,66500,255000,103000,55000,112400,81030,71900]})

df

"""Calculate and display familywise gross monthly income.

"""

df.groupby('Family Name')['Income'].sum()

"""Display the highest and lowest monthly income for each family name"""

df.groupby('Family Name')['Income'].min()

df.groupby('Family Name')['Income'].max()

"""Calculate and display monthly income of all members earning income less than Rs. 80000.00."""

df1 = df[df['Income']<80000]

df1

"""Display total number of females along with their average monthly income"""

df.groupby('Gender').agg({'Gender': 'count', 'Income': 'mean'})

"""Delete rows with Monthly income less than the average income of all members"""

df['Income'].mean()

df = df[df['Income'] >= df['Income'].mean()]
df

"""Q5 Using Iris data, plot the following with proper legend and axis labels: (Download IRIS data from:
https://archive.ics.uci.edu/ml/datasets/iris or import it from sklearn datasets)

"""

import seaborn as sns

"""Load data into pandas’ data frame. Use pandas.info () method to look at the info on datatypes in the
dataset
"""

iris = sns.load_dataset('iris')

iris.head()

iris.info()

"""Find the number of missing values in each column (Check number of null values in a column using
df.isnull().sum())
"""

iris.isnull().sum()

"""Plot bar chart to show the frequency of each class label in the data"""

# sns.barplot()



"""Draw a scatter plot for Petal Length vs Sepal Length and fit a regression line"""

sns.scatterplot(x = "petal_length",y = 'sepal_length',data = iris)

sns.regplot(x='sepal_length', y='petal_length', data=iris)

"""Plot density distribution for feature Petal width."""

sns.displot(iris['petal_width'],kde = True, bins = 15)

sns.kdeplot(iris['petal_width'], fill = True)

"""Use a pair plot to show pairwise bivariate distribution in the Iris Dataset."""

sns.pairplot(iris)

"""Draw heatmap for any two numeric attribute"""

sns.heatmap(iris.corr())

sns.heatmap(iris[['petal_length','sepal_length']])

"""Compute mean, mode, median, standard deviation, confidence interval and standard error for each
numeric feature
"""

iris.mean()

iris.mode()

iris.median()

iris.std()

"""Compute correlation coefficients between each pair of features and plot heatmap"""

iris.corr()

"""Using Titanic dataset, to do the following"""

titanic = sns.load_dataset('titanic')

titanic.head()

"""Clean the data by dropping the column which has the largest number of missing values"""

titanic.isnull().sum()

titanic.drop(['deck'],axis = 1)

"""Find total number of passengers with age more than 30"""

len(titanic[titanic['age']>30])

"""Find total fare paid by passengers of second class"""

titanic[titanic['class'] == 'Second']

titanic.groupby(['class'])['fare'].sum()['Second']

"""Compute descriptive statistics for age attribute gender wis"""

titanic.groupby(['sex']).agg({'age':'describe'})

df = titanic[titanic['sex'] == 'male']
df

"""Draw a scatter plot for passenger fare paid by Female and Male passengers separately"""

sns.scatterplot(x = 'sex', y ='fare', data = df )

sns.scatterplot(x = 'sex', y = 'fare',data = titanic, hue= 'sex')

"""Compare density distribution for features age and passenger fare"""

sns.kdeplot(y= 'fare' , x ='age',data = titanic, fill= True)

"""Draw the pie chart for three groups labelled as class 1, class 2, class 3 respectively displayed in different
colours. The occurrence of each group converted into percentage should be displayed in the pie chart.
Appropriately Label the chart

Find % of survived passengers for each class and answer the question “Did class play a role in survival?”.
"""

titanic.groupby('pclass')['survived'].mean()*100

"""Q4 Consider two excel files having attendance of two workshops, each of duration 5 days. Each file has three
fields ‘Name’, ‘Date, duration (in minutes) where names may be repetitve within a file. Note that duration may
take one of three values (30, 40, 50) only. Import the data into two data frames and do the following:
"""

import pandas as pd

file1 = pd.read_excel('/content/1.xlsx')

file2 = pd.read_excel('/content/3.xlsx')

file1

file2

"""Perform merging of the two data frames to find the names of students who had attended both
workshops
"""

attended_both = pd.merge(file1,file2, on ='Name', how = 'inner')
attended_both

attended_both['Name'].unique()

"""Find names of all students who have attended a single workshop only"""

attended_either = pd.merge(file1, file2, on = 'Name', how= 'outer')
attended_either

"""Merge two data frames row-wise and find the total number of records in the data frame"""

pd.concat([file1, file2],ignore_index = True).count()

"""Merge two data frames row-wise and use two columns viz. names and dates as multi-row indexes.
Generate descriptive statistics for this hierarchical data frame.

"""

file2.set_index(['Name','Date'])

file1.set_index(['Name','Date'])

df = pd.concat([file1.set_index(['Name','Date']),file2.set_index(['Name','Date'])])
df

df.describe()