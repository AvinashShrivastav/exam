# -*- coding: utf-8 -*-
"""FINALDAV.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12KcwILKpvpNKorJI95EODFV1IjFCfIdN

# **PRACTICAL 2 SERIES**
"""

import numpy as np
import pandas as pd

s = pd.Series([10,30,20,40,50])
print("og series:\n", s)
print("sorting index wise:\n", s.sort_index())
print("sorting values wise:\n", s.sort_values())

s = pd.Series([10, 20, 30, 40, 50])

print("Minimum value:", s.min())
print("Minimum value index:", s.idxmin())

print("Maximum value:", s.max())
print("Maximum value index:", s.idxmax())

s = pd.Series([10,20,40,50,10,30,20])
print("og series: \n", s)
print("min ranks assigned: \n", s.rank(method='first'))
print("max ranks assigned: \n", s.rank(method='max'))

"""# PRACTICAL 3 DATAFRAME"""

# import numpy as np
# import pandas as pd
# data = {'cols1': np.random.randint(1, 100, size=(50)),
#          'cols2': np.random.randint(1, 100, size=(50)),
#           'cols3': np.random.randint(1, 100, size=(50))}
# df = pd.DataFrame(data)
# non_ind = df.sample(frac=0.1, axis=0).index
# df.loc[non_ind]=np.nan
# print("the dataframe is: \n", df)
# # display(df)
# print("missing values are: \n", df.isnull().sum())
# df = df.dropna(axis=1, thresh=len(df) - 5)

# PRACTICAL 3


import pandas as pd
import numpy as np

# Set a seed for reproducibility
np.random.seed(42)

# Step 1: Create a data frame with random numeric data
data = {'Column1': np.random.rand(50),
        'Column2': np.random.rand(50),
        'Column3': np.random.rand(50)}

df = pd.DataFrame(data)

# Step 2: Replace 10% of the values with null values
null_indices = np.random.choice(df.size, size=int(0.1 * df.size), replace=False)
df.values.ravel()[null_indices] = np.nan

# a. Identify and count missing values
missing_values_count = df.isnull().sum()
print("Missing values count:\n", missing_values_count)

# b. Drop columns with more than 5 null values
df = df.dropna(axis=1, thresh=len(df) - 5)

# c. Identify the row label having the maximum sum and drop that row
max_sum_row_label = df.sum(axis=1).idxmax()
df = df.drop(index=max_sum_row_label)

# d. Sort the data frame based on the first column
df = df.sort_values(by='Column1')

# e. Remove duplicates from the first column
df = df.drop_duplicates(subset='Column1')

# f. Find correlation and covariance
correlation = df['Column1'].corr(df['Column2'])
covariance = df['Column2'].cov(df['Column3'])
print("Correlation between Column1 and Column2:", correlation)
print("Covariance between Column2 and Column3:", covariance)

# g. Discretize the second column into 5 bins
df['Column2_bins'] = pd.cut(df['Column2'], bins=5)

# Display the final data frame
print("\nFinal Data Frame:")
print(df)

states = [' Alabama ', 'Georgia!', 'Georgia', 'georgia', 'FlOrIda', 'south carolina##', 'West virginia?']
import re
def clean_str(strings):
  result=[]
  for value in strings:
    value=value.strip()
    value=re.sub('[?#!]', '', value)
    value=value.title()
    result.append(value)
  return result

clean_str(states)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df=pd.DataFrame([[1,1,1],[2,2,2],[1,2,1], [2,1,1]],
                index=['one','two','three','four'],
                columns=pd.Index(['A','B','C'],name='MyPlot'))
display(df)

fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(11, 6))
ax1.bar(df.index, df['A'], color='blue', label='A')
ax1.bar(df.index, df['B'], color='green', label='B')
ax1.bar(df.index, df['C'], color='red', label='C')

ax1.set_xlabel('Index')
ax1.set_ylabel('Values')
ax1.set_title('Bar Plot')
ax1.legend()

ax2.barh(df.index, df['A'], color='blue', label='A')
ax2.barh(df.index, df['B'], color='green', label='B')
ax2.barh(df.index, df['C'], color='red', label='C')

ax2.set_xlabel('Values')
ax2.set_ylabel('Index')
ax2.set_title('Horizontal Bar Plot')
ax2.legend()

fig.suptitle('Bar Plot and Horizontal Bar Plot')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

iris = sns.load_dataset('iris')

plt.figure(figsize=(10, 6))

sns.scatterplot(x='petal_length', y='sepal_length', data=iris, label='Petal Length vs Sepal Length')

plt.plot([min(iris['petal_length']), max(iris['petal_length'])],
         [min(iris['sepal_length']), max(iris['sepal_length'])],
         'r--', label='Dashed Line')
plt.scatter(iris['petal_length'], iris['sepal_width'], color='green', s=10, label='Green Marker (Size 10)')


plt.title('Scatter Plot of Iris Dataset')
plt.xlabel('Petal Length')
plt.ylabel('Sepal Length')


plt.legend()
plt.show()

#DATAFRAME FROM LISTS
import pandas as pd
data = [10,12,15,19,89]
df = pd.DataFrame(data, columns = ['Numbers'])
display(df)

#DATAFRAME FROM LIST OF LISTS
data1 = [[52,56], [58,35], [87,20]]
df1 = pd.DataFrame(data1, columns=['Age son', 'Age dawson'])
display(df1)

#DATAFRAME FROM DICTIONARY
data2 = {'Name': ['sham', 'pam', 'jim', 'lincoln'],
         'Age':[12,56,34,35]}

df2 = pd.DataFrame(data2)
display(df2)

#DATAFRAME FROM SERIES
data3 = pd.Series([10,67,28,30,98])
df3 = pd.DataFrame(data3)
display(df3)

#DATAFRAME USING RANDOM NUMBERS
import pandas as pd
import numpy as np

data4 = {'A': np.random.rand(4),
        'B': np.random.randint(1, 58, 4),
        'C': np.random.choice(['X', 'Y', 'Z'], 4)}

df4 = pd.DataFrame(data4)
display(df4)

# Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the Titanic dataset
url = "https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv"
titanic_data = pd.read_csv(url)
display(titanic_data)
# a. Clean the data by dropping the column which has the largest number of missing values
titanic_data.dropna(axis=1, inplace=True)

# b. Find the total number of passengers with age more than 30
passengers_age_gt_30 = titanic_data[titanic_data['Age'] > 30].shape[0]
print(f"Total number of passengers with age more than 30: {passengers_age_gt_30}")

# c. Find the total fare paid by passengers of the second class
total_fare_second_class = titanic_data[titanic_data['Pclass'] == 2]['Fare'].sum()
print(f"Total fare paid by passengers of the second class: {total_fare_second_class}")

# d. Compare the number of survivors of each passenger class
survivors_by_class = titanic_data.groupby('Pclass')['Survived'].sum()
print("Number of survivors by class:")
print(survivors_by_class)

# e. Compute descriptive statistics for the age attribute gender-wise
descriptive_stats_age_gender = titanic_data.groupby('Sex')['Age'].describe()
print("Descriptive statistics for age attribute gender-wise:")
print(descriptive_stats_age_gender)

# f. Draw a scatter plot for passenger fare paid by Female and Male passengers separately
sns.scatterplot(x='Fare', y='Sex', data=titanic_data)
plt.title('Scatter plot of Fare paid by Female and Male passengers')
plt.show()

# g. Compare density distribution for features age and passenger fare
plt.figure(figsize=(10, 6))
sns.kdeplot(titanic_data['Age'], label='Age', fill=True)
sns.kdeplot(titanic_data['Fare'], label='Fare', fill=True)
plt.title('Density Distribution of Age and Fare')
plt.legend()
plt.show()

# h. Draw the pie chart for three groups labeled as class 1, class 2, class 3
class_counts = titanic_data['Pclass'].value_counts()
plt.pie(class_counts, labels=['Class 1', 'Class 2', 'Class 3'], autopct='%1.1f%%', colors=['gold', 'lightcoral', 'lightskyblue'])
plt.title('Pie Chart of Passenger Class Distribution')
plt.show()

# i. Find % of survived passengers for each class
survival_percentage_by_class = titanic_data.groupby('Pclass')['Survived'].mean() * 100
print("Percentage of survived passengers for each class:")
print(survival_percentage_by_class)

max = titanic_data("Fare").max()

def max_fare_by_gender(data):
    # Find the index of the maximum fare for male and female passengers
    idx_max_fare_male = data[data['Sex'] == 'male']['Fare'].idxmax()
    idx_max_fare_female = data[data['Sex'] == 'female']['Fare'].idxmax()

    # Get the maximum fare values and their indices for male and female passengers
    max_fare_male = data.loc[idx_max_fare_male, 'Fare']
    max_fare_female = data.loc[idx_max_fare_female, 'Fare']

    return max_fare_male, idx_max_fare_male, max_fare_female, idx_max_fare_female

# Example usage
max_fares = max_fare_by_gender(titanic_data)
print("Max Fare for Male Passenger (Index: {}): {}".format(max_fares[1], max_fares[0]))
print("Max Fare for Female Passenger (Index: {}): {}".format(max_fares[3], max_fares[2]))

import pandas as pd

ages = pd.Series([21, 25, 26, 27, 18, 13, 77, 41, 51, 65, 11, 22])
bins = [15, 25, 35, 45, 55]
counts = pd.cut(ages, bins).value_counts()
print(counts)

# *PRAC1*
import numpy as np

ARR1 = np.random.rand(5,5)
mean = np.mean(ARR1, axis=1)
st_dev = np.std(ARR1, axis=1)
var = np.var(ARR1, axis=1)
print("Mean:", mean)
print("Standard Deviation:", st_dev)
print("Variance:", var)

m = int(input("Enter m:"))
n = int(input("Enter n:"))
arr = np.random.randint(1,10, (m,n))
display(arr)
print("Shape:", arr.shape )
print("Type:", type(arr))
print("Datatype:", arr.dtype)

reshape_arr = arr.reshape(n,m)
display(reshape_arr)



arr2 = np.array([1, 0, np.nan, 2, 0, 4, 5])
arr2

arr = np.array([1, 0, np.nan, 2, 0, 4, 5])

zero_indices = np.where(arr == 0)
non_zero_indices = np.where(arr != 0)
nan_indices = np.where(np.isnan(arr))

print("Zero indices:", zero_indices)
print("Non-zero indices:", non_zero_indices)
print("NaN indices:", nan_indices)

arr1 = np.random.rand(10)
arr2 = np.random.rand(10)
arr3 = np.random.rand(10)
arr4 = arr3-arr2
arr5 = arr1*2

cov14 = np.cov(arr1, arr4)[0,1]
corr14 = np.corrcoef(arr1, arr4)[0, 1]
cov15 = np.cov(arr1, arr5)[0, 1]
corr15 = np.corrcoef(arr1, arr5)[0, 1]

print("Co-variance between Array1 and Array4:", cov14)
print("Correlation between Array1 and Array4:", corr14)
print("Co-variance between Array1 and Array5:", cov15)
print("Correlation between Array1 and Array5:", corr15)

arr1 = np.random.rand(10)
arr2 = np.random.rand(10)

sum1 = np.sum(arr1[:5]) + np.sum(arr2[:5])
prod1 = np.prod(arr1[5:]) * np.prod(arr2[5:])

print("Sum of first half:", sum1)
print("Product of second half:", prod1)

arr = np.random.rand(1000)

mem_arr = arr.nbytes

print("Memory: ", mem_arr, "bytes")

# PRAC2
import pandas as pd

s = pd.Series([10, 5, 8, 3, 7])
print(s.sort_index())
print(s.sort_values())

N = int(input("Enter number of elements: "))

s = pd.Series(np.random.randint(1,100,size=N))
display(s)

min_rank1 = s.rank(method = "first")
max_rank1 = s.rank(method="first")
min_rankmax = s.rank(method ="max", ascending=False)
max_rankmax = s.rank(method ="max", ascending=False)

print("\nMinimum rank with 'first' method:", min_rank1.min())
print("Maximum rank with 'first' method:", max_rank1.max())
print("Minimum rank with 'max' method:", min_rankmax.min())
print("Maximum rank with 'max' method:", max_rankmax.max())

s = pd.Series([10, 5, 8, 3, 7])

print("Index of minimum element:", s.idxmin())
print("Index of maximum element:", s.idxmax())

import pandas as pd
import numpy as np

# Creating sample data frames
data1 = {'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'David'],
         'Date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-01', '2023-01-03']),
         'duration': [30, 40, 50, 30, 40]}

data2 = {'Name': ['Alice', 'Bob', 'Charlie', 'Eve', 'Frank'],
         'Date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-01', '2023-01-03']),
         'duration': [30, 40, 50, 30, 40]}

df1 = pd.DataFrame(data1)
df2 = pd.DataFrame(data2)
display(df1)
display(df2)

# a. Perform merging of the two data frames to find the names of students who had attended both workshops.
both_workshops = pd.merge(df1, df2, on=['Name', 'Date', 'duration'], how='inner')['Name'].unique()
print("Names of students who attended both workshops:", both_workshops)

# b. Find names of all students who have attended a single workshop only.
single_workshop = pd.concat([df1, df2]).drop_duplicates(keep=False)['Name'].unique()
print("Names of students who attended a single workshop only:", single_workshop)

# c. Merge two data frames row-wise and find the total number of records in the data frame.
merged_row_wise = pd.concat([df1, df2], ignore_index=True)
total_records = len(merged_row_wise)
print("Total number of records after merging row-wise:", total_records)

# d. Merge two data frames row-wise and use two columns viz. names and dates as multi-row indexes.
merged_hierarchical = pd.concat([df1.set_index(['Name', 'Date']), df2.set_index(['Name', 'Date'])], axis=0)
# Generate descriptive statistics for the hierarchical data frame
descriptive_stats = merged_hierarchical.groupby(['Name', 'Date']).describe()
print("Descriptive statistics for hierarchical data frame:\n", descriptive_stats)

import pandas as pd

# Creating the DataFrame
data = {'FamilyName': ['Shah', 'Vats', 'Vats', 'Kumar', 'Vats', 'Kumar', 'Shah', 'Shah', 'Kumar', 'Vats'],
        'Gender': ['Male', 'Male', 'Female', 'Female', 'Female', 'Male', 'Male', 'Female', 'Female', 'Male'],
        'MonthlyIncome': [44000.00, 65000.00, 43150.00, 66500.00, 255000.00, 103000.00, 55000.00, 112400.00, 81030.00, 71900.00]}

df = pd.DataFrame(data)

# a. Calculate and display familywise gross monthly income.
familywise_income = df.groupby('FamilyName')['MonthlyIncome'].sum()
print("Familywise Gross Monthly Income:\n", familywise_income)

# b. Display the highest and lowest monthly income for each family name
highest_income = df.groupby('FamilyName')['MonthlyIncome'].max()
lowest_income = df.groupby('FamilyName')['MonthlyIncome'].min()
print("\nHighest Monthly Income:\n", highest_income)
print("\nLowest Monthly Income:\n", lowest_income)

# c. Calculate and display monthly income of all members earning income less than Rs. 80000.00.
income_less_than_80000 = df[df['MonthlyIncome'] < 80000.00]
print("\nMonthly Income of Members Earning Less than Rs. 80000.00:\n", income_less_than_80000)

# d. Display total number of females along with their average monthly income
female_stats = df[df['Gender'] == 'Female'].groupby('Gender').agg({'MonthlyIncome': ['count', 'mean']})
print("\nTotal Number of Females and their Average Monthly Income:\n", female_stats)

# e. Delete rows with Monthly income less than the average income of all members
average_income = df['MonthlyIncome'].mean()
df = df[df['MonthlyIncome'] >= average_income]
print("\nDataFrame after Deleting Rows with Monthly Income less than the Average:\n", df)